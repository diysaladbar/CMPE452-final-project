{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Libraries**","metadata":{}},{"cell_type":"code","source":"# Daniel Jang, 20096632, 17DDHJ\n# CMPE452 Project Group 6 ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport random as random\nimport pandas as pd\nimport cv2\nimport os\nimport matplotlib.pyplot as plt\nfrom PIL import Image, ImageDraw, ImageEnhance\n\nfrom tensorflow.keras import utils\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\nfrom tensorflow.keras import Model\nfrom tensorflow.keras import datasets, layers, models\nfrom tensorflow.keras.utils import to_categorical\n\nimport seaborn as sns\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score","metadata":{"execution":{"iopub.status.busy":"2021-12-09T20:05:31.312481Z","iopub.execute_input":"2021-12-09T20:05:31.313202Z","iopub.status.idle":"2021-12-09T20:05:39.235107Z","shell.execute_reply.started":"2021-12-09T20:05:31.313074Z","shell.execute_reply":"2021-12-09T20:05:39.23417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Preprocessing**","metadata":{}},{"cell_type":"code","source":"# storing dataset path names\nsample_path = \"/kaggle/input/state-farm-distracted-driver-detection/sample_submission.csv\"\nimgs_list_path = \"/kaggle/input/state-farm-distracted-driver-detection/driver_imgs_list.csv\"\ntrain_path = \"/kaggle/input/state-farm-distracted-driver-detection/imgs/train\"\ntest_path = \"/kaggle/input/state-farm-distracted-driver-detection/imgs/test\"\n\n# read csv file\ndriver_imgs_list = pd.read_csv(imgs_list_path)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T20:05:39.237667Z","iopub.execute_input":"2021-12-09T20:05:39.238031Z","iopub.status.idle":"2021-12-09T20:05:39.289197Z","shell.execute_reply.started":"2021-12-09T20:05:39.237988Z","shell.execute_reply":"2021-12-09T20:05:39.287996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# global variables\nimg_width, img_height = (64, 64)\nmodel_input_shape = (img_width, img_height, 3)\ninput_image = (img_width, img_height)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T20:05:39.290887Z","iopub.execute_input":"2021-12-09T20:05:39.291286Z","iopub.status.idle":"2021-12-09T20:05:39.295429Z","shell.execute_reply.started":"2021-12-09T20:05:39.291252Z","shell.execute_reply":"2021-12-09T20:05:39.294823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sort class names and images \ndef pair_sort(className,values):\n    for j in range(0,len(className)-1):\n        for i in range(0,len(className)-1):\n            if values[i] > values[i+1]:\n                temp =  values[i+1]\n                values[i+1] = values[i]\n                values[i] = temp\n\n                N_temp =  className[i+1]\n                className[i+1] = className[i]\n                className[i] = N_temp\n    \n    return className,values","metadata":{"execution":{"iopub.status.busy":"2021-12-09T20:05:39.296871Z","iopub.execute_input":"2021-12-09T20:05:39.297229Z","iopub.status.idle":"2021-12-09T20:05:39.307538Z","shell.execute_reply.started":"2021-12-09T20:05:39.297198Z","shell.execute_reply":"2021-12-09T20:05:39.306698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib.pyplot import figure\nfigure(num=None, figsize=(15, 5), dpi=80, facecolor='w', edgecolor='k')\n\n# store list of class names\nclass_names = np.unique(driver_imgs_list['classname'])\n\n# store list of images separated by class name\nclass_image_list = [len(driver_imgs_list[driver_imgs_list['classname'] == current_class]) for current_class in class_names]\n\nclass_names,class_image_list=  pair_sort(class_names,class_image_list)\n\n# display the number of files associated with each class type\nplt.suptitle('Number of images per Class')\nplt.bar(class_names,class_image_list,color=(0.2, 0.4, 0.6, 0.6))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-09T20:05:39.309617Z","iopub.execute_input":"2021-12-09T20:05:39.310168Z","iopub.status.idle":"2021-12-09T20:05:39.658761Z","shell.execute_reply.started":"2021-12-09T20:05:39.310129Z","shell.execute_reply":"2021-12-09T20:05:39.657735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib.pyplot import figure\n\n# similar code to previous block\nsub_names = np.unique(driver_imgs_list['subject'])\nsub_image_list = [len(driver_imgs_list[driver_imgs_list['subject'] == current_sub]) for current_sub in sub_names]\nsub_names,sub_image_list=  pair_sort(sub_names,sub_image_list)\n\nfigure(num=None, figsize=(15, 10), dpi=80, facecolor='w', edgecolor='k')\n\ny_pos = np.arange(len(sub_names))\n\n# plt.barh(y_pos, sub_image_list,color=(0.2, 0.4, 0.6, 0.6))\n \n# plt.yticks(y_pos,sub_names )\n# plt.suptitle('Number of images per subject')\n\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-09T20:05:39.660177Z","iopub.execute_input":"2021-12-09T20:05:39.660475Z","iopub.status.idle":"2021-12-09T20:05:39.808069Z","shell.execute_reply.started":"2021-12-09T20:05:39.660443Z","shell.execute_reply":"2021-12-09T20:05:39.807037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load image from path\ndef load_image(path):\n    read_path =  train_path + \"/\" + path\n    image = Image.open(read_path)\n    image = image.resize(input_image)\n\n    return np.asarray(image)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T20:05:39.809635Z","iopub.execute_input":"2021-12-09T20:05:39.810104Z","iopub.status.idle":"2021-12-09T20:05:39.815079Z","shell.execute_reply.started":"2021-12-09T20:05:39.810069Z","shell.execute_reply":"2021-12-09T20:05:39.814164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function to display images\ndef show_images(image_ids,class_names):\n    pixels = [load_image(path) for path in image_ids]\n    num_of_images = len(image_ids)\n    fig, axes = plt.subplots(\n        1, \n        num_of_images, \n        figsize=(5 * num_of_images, 5 * num_of_images),\n    )\n    print(fig, axes)\n    for i, image_pixels in enumerate(pixels):\n        axes[i].imshow(image_pixels)\n        axes[i].axis(\"off\")\n        axes[i].set_title(class_names[i])","metadata":{"execution":{"iopub.status.busy":"2021-12-09T20:05:39.816636Z","iopub.execute_input":"2021-12-09T20:05:39.817138Z","iopub.status.idle":"2021-12-09T20:05:39.826531Z","shell.execute_reply.started":"2021-12-09T20:05:39.81709Z","shell.execute_reply":"2021-12-09T20:05:39.825597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# display one image from each class\nsub_names_imgs = [ current_class+\"/\"+driver_imgs_list[driver_imgs_list['classname'] == current_class]['img'].values[0] for current_class in class_names]\nshow_images(sub_names_imgs[:5],class_names[:5])\nshow_images(sub_names_imgs[5:],class_names[5:])","metadata":{"execution":{"iopub.status.busy":"2021-12-09T20:05:39.828321Z","iopub.execute_input":"2021-12-09T20:05:39.82884Z","iopub.status.idle":"2021-12-09T20:05:40.908582Z","shell.execute_reply.started":"2021-12-09T20:05:39.828788Z","shell.execute_reply":"2021-12-09T20:05:40.907719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# init empty lists to store training and test sets\nx_train = []\ny_train = []\n\nx_val = []\ny_val = []\n\n# split rate controls how much of the dataset is used\nsplit_rate = 0.8\n# split_rate = 0.1\n\n# pick \nfor current_class in class_names:\n    select_df = driver_imgs_list[driver_imgs_list['classname'] == current_class ]\n    image_list = select_df['img'].values\n    image_list = shuffle(image_list)\n    \n    # split truncated dataset into test and validation sets\n    train_amount = int(len(image_list)*split_rate)\n    train_list = image_list[:train_amount]\n    val_list = image_list[train_amount:]\n    # val_list = image_list[2200:]\n    \n    # load images into respective sets\n    for filename in train_list:\n        x_train.append(load_image(current_class+\"/\"+filename))\n        y_train.append(current_class.replace('c',''))\n\n    for filename in val_list:\n        x_val.append(load_image(current_class+\"/\"+filename))\n        y_val.append(current_class.replace('c',''))\n\n# variables to feed into model\nx_train = np.asarray(x_train)\ny_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\nx_val = np.asarray(x_val)\ny_val =tf.keras.utils.to_categorical(y_val, num_classes=10)\n\nprint(\"Train x Shape: \",x_train.shape)\nprint(\"Test x Shape: \",x_val.shape)\nprint(\"Train y Shape: \",y_train.shape)\nprint(\"Test y Shape: \",y_val.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T20:05:40.910295Z","iopub.execute_input":"2021-12-09T20:05:40.910816Z","iopub.status.idle":"2021-12-09T20:11:17.361641Z","shell.execute_reply.started":"2021-12-09T20:05:40.910768Z","shell.execute_reply":"2021-12-09T20:11:17.360704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Model**","metadata":{}},{"cell_type":"code","source":"#general vgg16 structure\n\n# model = models.Sequential()\n\n# model.add(layers.Conv2D(64, activation='relu'))\n# model.add(layers.Conv2D(64, activation='relu'))\n# model.add(layers.MaxPooling2D())\n          \n# model.add(layers.Conv2D(128, activation='relu'))\n# model.add(layers.Conv2D(128, activation='relu'))\n# model.add(layers.MaxPooling2D())\n\n# model.add(layers.Conv2D(256, activation='relu'))\n# model.add(layers.Conv2D(256, activation='relu'))\n# model.add(layers.Conv2D(256, activation='relu'))\n# model.add(layers.MaxPooling2D())\n\n# model.add(layers.Conv2D(512, activation='relu'))\n# model.add(layers.Conv2D(512, activation='relu'))\n# model.add(layers.Conv2D(512, activation='relu'))\n# model.add(layers.MaxPooling2D())\n\n# model.add(layers.Conv2D(512, activation='relu'))\n# model.add(layers.Conv2D(512, activation='relu'))\n# model.add(layers.Conv2D(512, activation='relu'))\n# model.add(layers.MaxPooling2D())\n          \n# model.add(Dense(4096, activation='relu'))\n# model.add(Dense(1000, activation='relu'))\n# model.add(Dense(10, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2021-12-09T20:11:17.36324Z","iopub.execute_input":"2021-12-09T20:11:17.363521Z","iopub.status.idle":"2021-12-09T20:11:17.36848Z","shell.execute_reply.started":"2021-12-09T20:11:17.363488Z","shell.execute_reply":"2021-12-09T20:11:17.367567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# modified VGG\n# reduced number of convolutional layers, dropout layers added in attempt to reduce overtraining\n\nmodel = models.Sequential()\n\nmodel.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(64,64,3), kernel_initializer='glorot_normal'))\nmodel.add(MaxPooling2D(pool_size=2))\n# model.add(Dropout(0.5))\n\nmodel.add(Conv2D(filters=128, kernel_size=2, padding='same', activation='relu', kernel_initializer='glorot_normal'))\nmodel.add(MaxPooling2D(pool_size=2))\n# model.add(Dropout(0.5))\n\nmodel.add(Conv2D(filters=256, kernel_size=2, padding='same', activation='relu', kernel_initializer='glorot_normal'))\nmodel.add(MaxPooling2D(pool_size=2))\n# model.add(Dropout(0.5))\n\nmodel.add(Conv2D(filters=512, kernel_size=2, padding='same', activation='relu', kernel_initializer='glorot_normal'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Dropout(0.5))\n\nmodel.add(Flatten())\nmodel.add(Dense(500, activation='relu', kernel_initializer='glorot_normal'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation='softmax', kernel_initializer='glorot_normal'))","metadata":{"execution":{"iopub.status.busy":"2021-12-09T20:11:17.370347Z","iopub.execute_input":"2021-12-09T20:11:17.371061Z","iopub.status.idle":"2021-12-09T20:11:17.661981Z","shell.execute_reply.started":"2021-12-09T20:11:17.371019Z","shell.execute_reply":"2021-12-09T20:11:17.660859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-09T20:11:17.663396Z","iopub.execute_input":"2021-12-09T20:11:17.663664Z","iopub.status.idle":"2021-12-09T20:11:17.677317Z","shell.execute_reply.started":"2021-12-09T20:11:17.663634Z","shell.execute_reply":"2021-12-09T20:11:17.676179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n# model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-12-09T20:11:17.682045Z","iopub.execute_input":"2021-12-09T20:11:17.682425Z","iopub.status.idle":"2021-12-09T20:11:17.698976Z","shell.execute_reply.started":"2021-12-09T20:11:17.682379Z","shell.execute_reply":"2021-12-09T20:11:17.69752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# num_epochs = 30\nnum_epochs = 20\n\nmodel_history = model.fit(x = x_train,y=y_train,\n      validation_data=(x_val,y_val),\n      batch_size = 20,\n      #batch_size = 2,\n      epochs=num_epochs,\n      verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T20:11:17.701318Z","iopub.execute_input":"2021-12-09T20:11:17.701727Z","iopub.status.idle":"2021-12-09T21:06:29.648912Z","shell.execute_reply.started":"2021-12-09T20:11:17.701679Z","shell.execute_reply":"2021-12-09T21:06:29.647547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print graph of training accuracy and validation accuracy\nfig, (ax) = plt.subplots(1, 1, figsize=(8, 8))\nax.plot(model_history.history['accuracy'], color='b', label=\"Training accuracy\")\nax.plot(model_history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nax.set_xticks(np.arange(1, 20, 1))\n\nlegend = plt.legend(loc='best', shadow=True)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-09T21:06:29.651034Z","iopub.execute_input":"2021-12-09T21:06:29.65174Z","iopub.status.idle":"2021-12-09T21:06:29.944808Z","shell.execute_reply.started":"2021-12-09T21:06:29.651694Z","shell.execute_reply":"2021-12-09T21:06:29.943862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Analysis**","metadata":{}},{"cell_type":"code","source":"# evaluator function\ndef evaluator(test_y, pred_y):\n    print(confusion_matrix(test_y, pred_y))\n    print('accuracy score: ', accuracy_score(test_y, pred_y))\n    print('recall score: ', recall_score(test_y, pred_y, average='micro'))\n    print('precision score: ', precision_score(test_y, pred_y, average='micro'))\n    print('f1 score: ', f1_score(test_y, pred_y, average='micro'))","metadata":{"execution":{"iopub.status.busy":"2021-12-09T21:06:29.946261Z","iopub.execute_input":"2021-12-09T21:06:29.947246Z","iopub.status.idle":"2021-12-09T21:06:29.956169Z","shell.execute_reply.started":"2021-12-09T21:06:29.947192Z","shell.execute_reply":"2021-12-09T21:06:29.954361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print evaluator\ny_pred = model.predict(x_val)\nevaluator(np.argmax(y_val, axis=1), np.argmax(y_pred, axis=1))","metadata":{"execution":{"iopub.status.busy":"2021-12-09T21:06:29.958141Z","iopub.execute_input":"2021-12-09T21:06:29.958538Z","iopub.status.idle":"2021-12-09T21:06:40.7198Z","shell.execute_reply.started":"2021-12-09T21:06:29.958489Z","shell.execute_reply":"2021-12-09T21:06:40.718456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# comparison of accuracy and loss for training and validation\nfig, ax = plt.subplots(1, 2, figsize=(15, 5))\n\nax[0].set_title('Training')\nax[0].plot(model_history.history['accuracy'])\nax[0].plot(model_history.history['val_accuracy'])\n\nax[1].set_title('Validation')\nax[1].plot(model_history.history['loss'])\nax[1].plot(model_history.history['val_loss'])","metadata":{"execution":{"iopub.status.busy":"2021-12-09T21:06:40.72171Z","iopub.execute_input":"2021-12-09T21:06:40.72246Z","iopub.status.idle":"2021-12-09T21:06:41.11787Z","shell.execute_reply.started":"2021-12-09T21:06:40.722336Z","shell.execute_reply":"2021-12-09T21:06:41.116849Z"},"trusted":true},"execution_count":null,"outputs":[]}]}